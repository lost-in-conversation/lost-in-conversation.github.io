<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="LLMs Get Lost In Multi-Turn Conversation">
  <meta name="keywords" content="LLMs, Multi-Turn Conversation, Performance Degradation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LLMs Get Lost In Multi-Turn Conversation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">LLMs Get Lost In Multi-Turn Conversation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://tingofurro.github.io/">Philippe Laban</a><sup>*1</sup>,</span>
            <span class="author-block">
              <a href="https://rooa.github.io">Hiroaki Hayashi</a><sup>*2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=H_6RQ7oAAAAJ&hl=en">Yingbo Zhou</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/jenneville/">Jennifer Neville</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Microsoft Research,</span>
            <span class="author-block"><sup>2</sup>Salesforce Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            <!-- Code Link. -->
            <span class="link-block">
                <a href="viewer/"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-eye"></i>
                </span>
                <span>Viewer</span>
                </a>
            </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/microsoft/lost_in_conversation"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/microsoft/lost_in_conversation"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
      <!-- Teaser image -->
      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <img src="static/images/teaser.png" alt="Teaser">
          </div>
        </div>
      </div>
    </div>
  </section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Language Models (LLMs) are conversational interfaces. As such, LLMs have the potential to
            assist their users not only when they can fully specify the task at hand, but also to help them
            define, explore, and refine what they need through multi-turn conversational exchange. Although
            analysis of LLM conversation logs has confirmed that underspecification occurs frequently in
            user instructions, LLM evaluation has predominantly focused on the single-turn, fully-specified
            instruction setting. In this work, we perform large-scale simulation experiments to compare LLM
            performance in single- and multi-turn settings. Our experiments confirm that all the top open-
            and closed-weight LLMs we test exhibit significantly lower performance in multi-turn conversations
            compared to single-turn, with an average drop of 35% across six generation tasks. Analysis
            of 200,000+ simulated conversations decomposes the performance degradation into two components:
            a minor loss in aptitude and a significant increase in unreliability. We find that LLMs often
            make assumptions in early turns and prematurely attempt to generate final solutions, which
            they overly rely on. In simpler terms, we discover that
            <b>when LLMs take a wrong turn in a conversation, they get lost and do not recover</b>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>





<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
        @article{
            author = {Philippe Laban, Hiroaki Hayashi, Yingbo Zhou, Jeniffer Neville},
            title = {LLMs Get Lost In Multi-Turn Conversation},
            year = {2025},
        }
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
